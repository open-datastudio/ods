{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open data studio\n",
    "\n",
    "[Open data studio](https://open-datastudio.io) is a managed computing service on [Staroid](https://staroid.com). Run your machine learning and large scale data processing workloads without managing clusters and servers.\n",
    "\n",
    "[ods](https://github.com/open-datastudio/ods) library makes it easy to use in a Python environment. Currently, the library supports the following computing frameworks.\n",
    "\n",
    " - Apache Spark\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure\n",
    "\n",
    "First, you need a SKE (Star Kubernetes Engine) cluster from [staroid.com](https://staroid.com) and access token for it. SKE provides a fully managed, serverless Kubernetes namespace on the cloud.\n",
    "\n",
    "  - Sign up [staroid.com](https://staroid.com)\n",
    "  - Click 'Kubernetes' -> 'New Kubernetes cluster' to create a new SKE cluster. And set the `STAROID_SKE` environment variable.\n",
    "  - Get access token from the 'Account' -> ['Access tokens'](https://staroid.com/settings/accesstokens) menu. And set the `STAROID_ACCESS_TOKEN` environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"STAROID_SKE\"]=\"<your ske cluster name>\"\n",
    "os.environ[\"STAROID_ACCESS_TOKEN\"]=\"<your staroid access token>\"\n",
    "\n",
    "# optionally configure your aws key to test data on s3\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"]=\"\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"]=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you're ready to go!.\n",
    "Let's install and initialize the [ods](https://github.com/open-datastudio/ods) module."
   ]
  },
  {
   "source": [
    "## Install"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q ods\n",
    "\n",
    "import ods\n",
    "ods.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark cluster\n",
    "\n",
    "Getting a Spark cluster is simple. Create a spark session using ods library. The library will download Spark (3.x), configure it, create workers on the cloud, and connect to them automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cluster = ods.spark(\"spark1\", worker_num=2, delta=True) # you can replace 'spark1' to a unique name for the instance\n",
    "spark = my_cluster.session() # get spark session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! now you've got spark session powered by powerful worker machines running on the cloud.\n",
    "\n",
    "Load your data and run your job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run spark job any spark \n",
    "df = spark.createDataFrame([{\"hello\": \"world\"} for x in range(100)])\n",
    "df.show()"
   ]
  },
  {
   "source": [
    "Your spark session will create Spark executors in remote "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you have configured AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY, you can try load following data\n",
    "dataLocation = \"s3a://us-east-1.elasticmapreduce.samples/flightdata/input/\"\n",
    "df = spark.read.parquet(dataLocation)\n",
    "df.createOrReplaceTempView(\"flights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select flightdate, count(1) from flights group by flightdate order by flightdate desc\").show()"
   ]
  },
  {
   "source": [
    "## Instance management menu and Spark UI\n",
    "\n",
    "Open a [Instance management menu](https://staroid.com/g/open-datastudio/spark-serverless/instances). You'll find your spark-serverless cluster instance. Once you click, you'll see status of your executors.\n",
    "\n",
    "Also you can find link to Spark UI"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Spark session and clean up\n",
    "\n",
    "When the spark is no longer needed, you can stop the spark session and release executors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop() # stop spark session and release executors\n",
    "my_cluster.delete() # delete all cluster resources on the cloud."
   ]
  },
  {
   "source": [
    "## Documentation\n",
    "\n",
    "Visit http://open-datastudio.io/computing/spark/index.html for the documentation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get involved\n",
    "\n",
    "Open data studio is an open source project. Please give us feedback and feel free to get involved!\n",
    "\n",
    " - Feedbacks, questions - [ods issue tracker](https://github.com/open-datastudio/ods/issues)\n",
    " - Open data studio slack channel - [Join](https://join.slack.com/t/opendatastudio/shared_invite/zt-jq449y9j-DIPBteeWC15xBbQAqi4J4g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commercial support\n",
    "\n",
    "[Staroid](https://staroid.com) actively contributes to Open data studio and provides commercial support. Please [contact](https://staroid.com/site/contact)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}